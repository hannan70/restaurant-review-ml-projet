{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f27415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\machine-learning\\deep-learning-project\\Restaurant-Reviews-RNN-Problem\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Embedding, SimpleRNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02a18f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HANNAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HANNAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HANNAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7346c410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The ambience was good, food was quite good . h...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ambience is too good for a pleasant evening. S...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A must try.. great food great ambience. Thnx f...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soumen das and Arun was a great guy. Only beca...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food is good.we ordered Kodi drumsticks and ba...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Madhumathi Mahajan Well to start with nice cou...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>This place has never disappointed us.. The foo...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Bad rating is mainly because of \"Chicken Bone ...</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>I personally love and prefer Chinese Food. Had...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Checked in here to try some delicious chinese ...</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review Rating\n",
       "0     The ambience was good, food was quite good . h...      5\n",
       "1     Ambience is too good for a pleasant evening. S...      5\n",
       "2     A must try.. great food great ambience. Thnx f...      5\n",
       "3     Soumen das and Arun was a great guy. Only beca...      5\n",
       "4     Food is good.we ordered Kodi drumsticks and ba...      5\n",
       "...                                                 ...    ...\n",
       "9995  Madhumathi Mahajan Well to start with nice cou...      3\n",
       "9996  This place has never disappointed us.. The foo...    4.5\n",
       "9997  Bad rating is mainly because of \"Chicken Bone ...    1.5\n",
       "9998  I personally love and prefer Chinese Food. Had...      4\n",
       "9999  Checked in here to try some delicious chinese ...    3.5\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv(\"../../../dataset/Restaurant reviews.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1db4a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b80391b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review    0\n",
       "Rating    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "471776ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=df[df['Rating'] == \"Like\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faf1055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all rating into flot\n",
    "df['Rating'] = df['Rating'].apply(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "737e5608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable\n",
    "# 1 = Positive, 0 = Negative Review\n",
    "df['Target'] = df['Rating'].apply(lambda x: 1 if x > 3.0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1796f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Rating'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c70c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The ambience was good, food was quite good . h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ambience is too good for a pleasant evening. S...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A must try.. great food great ambience. Thnx f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soumen das and Arun was a great guy. Only beca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food is good.we ordered Kodi drumsticks and ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Target\n",
       "0  The ambience was good, food was quite good . h...       1\n",
       "1  Ambience is too good for a pleasant evening. S...       1\n",
       "2  A must try.. great food great ambience. Thnx f...       1\n",
       "3  Soumen das and Arun was a great guy. Only beca...       1\n",
       "4  Food is good.we ordered Kodi drumsticks and ba...       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0cb1bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "important_words = {\"not\", \"no\", \"nor\", \"never\"}\n",
    "final_stopwords = stop_words - important_words\n",
    "\n",
    "lemmatize = WordNetLemmatizer()\n",
    "\n",
    "# Clean the text\n",
    "corpus = []\n",
    "for i in range(0, len(df)):\n",
    "    reviews = re.sub('[^a-zA-Z]', ' ', df['Review'].iloc[i])\n",
    "    reviews = reviews.lower()\n",
    "    reviews = word_tokenize(reviews, language=\"english\")\n",
    "    reviews = [lemmatize.lemmatize(word) for word in reviews if word not in final_stopwords]\n",
    "    reviews = \" \".join(reviews).strip()\n",
    "    corpus.append(reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2e19115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vocabulary size\n",
    "voc_size = 10000\n",
    "\n",
    "# Use Tokenizer instead of one_hot\n",
    "tokenizer = Tokenizer(num_words=voc_size)\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "X = tokenizer.texts_to_sequences(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ecdfd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tokenizer\n",
    "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b373015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "max_length = 500\n",
    "X = pad_sequences(X, maxlen=max_length)\n",
    "y = df['Target']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0b9f610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\machine-learning\\deep-learning-project\\Restaurant-Reviews-RNN-Problem\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=voc_size, output_dim=128, input_length=max_length))\n",
    "model.add(SimpleRNN(128, activation=\"relu\", return_sequences=True))\n",
    "model.add(SimpleRNN(64, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c06fcad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 128)          1280000   \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 500, 128)          32896     \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 64)                12352     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1325313 (5.06 MB)\n",
      "Trainable params: 1325313 (5.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e7b137d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\machine-learning\\deep-learning-project\\Restaurant-Reviews-RNN-Problem\\venv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a9da164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup EarlyStopping\n",
    "earlystoping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e9ed947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From d:\\machine-learning\\deep-learning-project\\Restaurant-Reviews-RNN-Problem\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\machine-learning\\deep-learning-project\\Restaurant-Reviews-RNN-Problem\\venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "125/125 [==============================] - 26s 187ms/step - loss: 0.4661 - accuracy: 0.7726 - val_loss: 0.3048 - val_accuracy: 0.8810\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 24s 188ms/step - loss: 0.2144 - accuracy: 0.9166 - val_loss: 0.2897 - val_accuracy: 0.8739\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 23s 183ms/step - loss: 0.1339 - accuracy: 0.9515 - val_loss: 0.3577 - val_accuracy: 0.8805\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 24s 191ms/step - loss: 0.1025 - accuracy: 0.9630 - val_loss: 0.4328 - val_accuracy: 0.8795\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 26s 207ms/step - loss: 0.0889 - accuracy: 0.9677 - val_loss: 0.4187 - val_accuracy: 0.8654\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 26s 211ms/step - loss: 0.0933 - accuracy: 0.9689 - val_loss: 0.4480 - val_accuracy: 0.8694\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 27s 212ms/step - loss: 0.0557 - accuracy: 0.9813 - val_loss: 0.5409 - val_accuracy: 0.8669\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 26s 208ms/step - loss: 0.0433 - accuracy: 0.9863 - val_loss: 0.5564 - val_accuracy: 0.8739\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 27s 216ms/step - loss: 0.0691 - accuracy: 0.9753 - val_loss: 0.5213 - val_accuracy: 0.8689\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 28s 226ms/step - loss: 0.0441 - accuracy: 0.9852 - val_loss: 0.5820 - val_accuracy: 0.8599\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 28s 226ms/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.7486 - val_accuracy: 0.8508\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 28s 222ms/step - loss: 0.0454 - accuracy: 0.9852 - val_loss: 0.8188 - val_accuracy: 0.8599\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[earlystoping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3af08488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\machine-learning\\deep-learning-project\\Restaurant-Reviews-RNN-Problem\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model.save(\"simple_rnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4ae72fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 35ms/step - loss: 0.2897 - accuracy: 0.8739\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00e87f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"simple_rnn.h5\")\n",
    "with open(\"tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e993076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    review = review.lower()\n",
    "    review = word_tokenize(review, language=\"english\")\n",
    "    review = [lemmatize.lemmatize(word) for word in review if word not in final_stopwords]\n",
    "    cleaned_text = \" \".join(review).strip()\n",
    "    encoded_review = tokenizer.texts_to_sequences([cleaned_text])\n",
    "    padded_review = pad_sequences(encoded_review, maxlen=max_length)\n",
    "    return padded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa77adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict function\n",
    "def predict_sentiment(review):\n",
    "    processed_input = preprocess_text(review)\n",
    "    prediction = model.predict(processed_input)\n",
    "    sentiment = 'Positive' if prediction[0][0] > 0.6 else 'Negative'\n",
    "    return sentiment, prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0655a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "Review Text: Hands down one of the best meals Iâ€™ve had in a long time. Everything was cooked to perfection and the flavors were out of this world.\n",
      "Sentiment: Positive\n",
      "Score: 0.73961276\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "example_review = \"Hands down one of the best meals Iâ€™ve had in a long time. Everything was cooked to perfection and the flavors were out of this world.\"\n",
    "sentiment, score = predict_sentiment(example_review)\n",
    "\n",
    "print(\"Review Text:\", example_review)\n",
    "print(\"Sentiment:\", sentiment)\n",
    "print(\"Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b35e4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
